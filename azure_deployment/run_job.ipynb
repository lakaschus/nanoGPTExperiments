{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = !az account show --query id --output tsv\n",
    "subscription_id = subscription_id[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConfigTree([('RESOURCE_GROUP', 'rg-llm-experiments'), ('WORKSPACE_NAME', 'yaol-llm-experiments'), ('REGION', 'eastus'), ('COMPUTE_VM', 'Standard_NC6s_v3'), ('COMPUTE_NAME', 'teslav100')])\n"
     ]
    }
   ],
   "source": [
    "# Get the resource group name and workspace name for the workspace from the config.conf file using pyhocon\n",
    "from pyhocon import ConfigFactory\n",
    "config = ConfigFactory.parse_file(\"config.conf\")\n",
    "resource_group = config.get_string(\"RESOURCE_GROUP\")\n",
    "workspace_name = config.get_string(\"WORKSPACE_NAME\")\n",
    "compute_name = config.get_string(\"COMPUTE_NAME\")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x7f939709a830>,\n",
      "         subscription_id=ea54fca2-3a3e-4b3b-91e7-a7bf971e0443,\n",
      "         resource_group_name=rg-llm-experiments,\n",
      "         workspace_name=yaol-llm-experiments)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from azure.ai.ml import MLClient, Input, Output\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "# NOTE: It's very import to always set the resource_group and workspace_name when creating the MLClient\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id=subscription_id, resource_group_name=resource_group, workspace_name=workspace_name\n",
    ")\n",
    "print(ml_client)\n",
    "\n",
    "from azureml.core import Workspace, Datastore\n",
    "\n",
    "ws = Workspace(subscription_id=subscription_id, resource_group=resource_group, workspace_name=workspace_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Params / Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../configs/azure_configs_debugging.json\") as f:\n",
    "    params = json.load(f)\n",
    "    train_params = params['train_params']\n",
    "    sample_params = params['sample_params']\n",
    "    dataset_params = params['dataset_params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "custom_env = Environment(\n",
    "    name='nano_gpt_env',\n",
    "    description=\"Custom environment for nano gpt training\",\n",
    "    conda_file=\"../environment.yml\",\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.8-cudnn8-ubuntu22.04\",\n",
    ")\n",
    "# ml_client.environments.create_or_update(custom_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# from azure.ai.ml.entities import Data\n",
    "# import os\n",
    "\n",
    "# def build_cmd(script, param_dict):\n",
    "#     return f\"python {script}\" + \"\".join(f\" --{k}\" if v is True else f\" --{k}={v}\" for k, v in param_dict.items())\n",
    "\n",
    "# def get_or_create_dataset(dataset_name):\n",
    "#     try:\n",
    "#         # Try to get the existing dataset\n",
    "#         dataset_train = ml_client.data.get(name=dataset_name + '_train', version=\"latest\")\n",
    "#         dataset_val = ml_client.data.get(name=dataset_name + '_val', version=\"latest\")\n",
    "#         print(f\"Dataset {dataset_name} already exists. Using existing version.\")\n",
    "#         return dataset_train, dataset_val\n",
    "#     except Exception:\n",
    "#         print(f\"Dataset {dataset_name} doesn't exist or not registered.\")\n",
    "        \n",
    "#         dataset_path = './data/' + dataset_name\n",
    "        \n",
    "#         if os.path.exists(dataset_path):\n",
    "#             print(f\"Dataset {dataset_name} already exists at {dataset_path}.\")\n",
    "#         else:\n",
    "#             print(f\"Dataset {dataset_name} doesn't exist yet locally, create it...\")\n",
    "#             cmd = build_cmd('../data/prepare.py', dataset_params)\n",
    "#             subprocess.run(cmd, shell=True)\n",
    "        \n",
    "#             # Create the dataset\n",
    "#         dataset_train = Data(\n",
    "#             name=dataset_name + '_train',\n",
    "#             description=f\"train dataset for {dataset_name}\",\n",
    "#             path=dataset_path + '/train.bin',\n",
    "#             type=\"uri_file\",\n",
    "#             version=\"latest\"\n",
    "#         )\n",
    "        \n",
    "#         dataset_val = Data(\n",
    "#             name=dataset_name + '_val',\n",
    "#             description=f\"val dataset for {dataset_name}\",\n",
    "#             path=dataset_path + '/val.bin',\n",
    "#             type=\"uri_file\",\n",
    "#             version=\"latest\"\n",
    "#         )\n",
    "\n",
    "#         ml_client.data.create_or_update(dataset_train)\n",
    "#         ml_client.data.create_or_update(dataset_val)\n",
    "#         print(f\"Dataset {dataset_name} has been registered/updated.\")\n",
    "#         return dataset_train, dataset_val\n",
    "\n",
    "# dataset_train, dataset_val = get_or_create_dataset(dataset_params['dataset_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset openwebtext-10k already exists. Using existing version.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from azure.ai.ml.entities import Data\n",
    "\n",
    "def build_cmd(script, param_dict):\n",
    "    return f\"python {script}\" + \"\".join(f\" --{k}\" if v is True else f\" --{k}={v}\" for k, v in param_dict.items())\n",
    "\n",
    "def create_dataset(dataset_name):\n",
    "    try:\n",
    "        # Try to get the existing dataset\n",
    "        dataset = ml_client.data.get(name=dataset_name, version=\"latest\")\n",
    "        print(f\"Dataset {dataset_name} already exists. Using existing version.\")\n",
    "    except Exception:\n",
    "        print(f\"Dataset {dataset_name} doesn't exist. Creating new dataset.\")\n",
    "        cmd = build_cmd('../src/data/prepare.py', dataset_params)\n",
    "        subprocess.run(cmd, shell=True)\n",
    "        dataset_folder_name = dataset_name.split(\"/\")[-1].replace(\"-\", \"_\")\n",
    "        dataset_path = '../src/data/' + dataset_folder_name\n",
    "            # Create the dataset\n",
    "        dataset = Data(\n",
    "            name=dataset_name,\n",
    "            description=f\"Dataset for {dataset_name}\",\n",
    "            path=dataset_path,\n",
    "            type=\"uri_folder\",\n",
    "            version=\"latest\"\n",
    "        )\n",
    "\n",
    "        ml_client.data.create_or_update(dataset)\n",
    "        print(f\"Dataset {dataset_name} has been registered/updated.\")\n",
    "\n",
    "create_dataset(dataset_params['dataset_id'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "train_cmd = build_cmd('train.py', train_params)\n",
    "\n",
    "# configure job\n",
    "train_job = command(\n",
    "    code=\"../src\",\n",
    "    command=train_cmd,\n",
    "    environment=custom_env,\n",
    "    compute=compute_name,\n",
    "    display_name=train_params[\"experiment_name\"],\n",
    "    experiment_name=train_params[\"experiment_name\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: the provided asset name 'nano_gpt_env' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'nano_gpt_env' will not be used for anonymous registration\n",
      "\u001b[32mUploading src (22.56 MBs): 100%|██████████| 22563007/22563007 [00:15<00:00, 1430255.18it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "returned_job = ml_client.create_or_update(train_job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_job = command(\n",
    "    code=\"../src\",\n",
    "    command=\"python train.py\",\n",
    "    inputs={\n",
    "        f\"{dataset_name} dataset\": Input(type=\"uri_folder\"),\n",
    "    },\n",
    "    outputs={\n",
    "        \"model\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "    }\n",
    "    environment=custom_env,\n",
    "    compute=compute_name,\n",
    "    display_name=train_params[\"experiment_name\"],\n",
    "    experiment_name=train_params[\"experiment_name\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
